{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastembed import SparseTextEmbedding\n",
    "from qdrant_client import QdrantClient, models\n",
    "import os\n",
    "import json\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from qdrant_client import QdrantClient\n",
    "client = QdrantClient(\"http://localhost:6333\", timeout=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"\"\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#queries = [\"How do I become a good computer science engineer?\", \"What causes nuclear reactions in the Sun?\"]\n",
    "MODEL_NAME = \"prithivida/Splade_PP_en_v1\"\n",
    "#MODEL_NAME= \"Qdrant/bm42-all-minilm-l6-v2-attentions\"\n",
    "#MODEL_NAME = \"Qdrant/bm25\"\n",
    "SPARSE_TYPE = \"bm42\"\n",
    "DATASET = \"quora\"\n",
    "COLLECTION_NAME = \"quora_collection\"\n",
    "\n",
    "DATASET = f\"/datasets/{DATASET}/queries.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_queries():\n",
    "    queries = {}\n",
    "\n",
    "    with open(DATASET, \"r\") as file:\n",
    "        for line in file:\n",
    "            row = json.loads(line)\n",
    "            queries[row[\"_id\"]] = row['text']\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = load_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this function encodes a query into a dense vector using openai embeddings\n",
    "def encode_dense_query(query):\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        model= \"text-embedding-ada-002\",  \n",
    "        azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "        openai_api_version=os.environ[\"OPENAI_API_VERSION\"],\n",
    "        openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    )\n",
    "    query_vector = embeddings.embed_query(query)\n",
    "    return query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function encodes a query into a sparse vector using a specified model (bm25/splade/BM42)\n",
    "def encode_sparse_query(query, model_name= MODEL_NAME): \n",
    "    model = SparseTextEmbedding(model_name)\n",
    "    embedding = list(model.query_embed(query))[0]\n",
    "    sparse_vector = models.SparseVector(values=embedding.values.tolist(), indices=embedding.indices.tolist())\n",
    "    return sparse_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hybrid_search(sparse_vector, dense_vector):\n",
    "    hybrid = client.query_points(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        prefetch=[models.Prefetch(\n",
    "            query=sparse_vector,\n",
    "            using=SPARSE_TYPE,\n",
    "            limit=10,\n",
    "            ),\n",
    "            models.Prefetch(\n",
    "                query=dense_vector,\n",
    "                using=\"openai\",\n",
    "                limit=10,\n",
    "                ),\n",
    "                ],\n",
    "                query=models.FusionQuery(fusion=models.Fusion.RRF),\n",
    "                )\n",
    "    return hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./quora_bm42_hyb.jsonl\", \"w\") as dense_out:\n",
    "    for idx,text in queries.items():\n",
    "        sparse_vector = encode_sparse_query(text)\n",
    "        dense_vector = encode_dense_query(text)\n",
    "        search_result = hybrid_search(sparse_vector,dense_vector)\n",
    "\n",
    "        hybrid_output = {\"query_id\": idx,\"results\":\n",
    "                        [{\"doc_id\": point.id,\"score\": point.score}\n",
    "                         for point in search_result.points]}\n",
    "        dense_out.write(json.dumps(hybrid_output) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
